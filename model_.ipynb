{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QGllbzLonLs",
        "outputId": "72b5179f-3a32-42da-cea7-b56b74544e0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Loaded with shape: (113705, 17)\n",
            "Preprocessing complete. Processed data shape: (113705, 57)\n",
            "Logistic Regression Model Trained.\n",
            "Random Forest Model Trained.\n",
            "Logistic Regression Accuracy: 0.7646282833020638\n",
            "Random Forest Accuracy: 0.7602310037523452\n",
            "Predictions from Logistic Regression: [1 1 0 ... 1 1 1]\n",
            "Predictions from Random Forest: [1 1 0 ... 0 1 1]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "import joblib\n",
        "\n",
        "class LoanStatusModel:\n",
        "    def __init__(self,data_path):\n",
        "        self.data_path = data_path\n",
        "        self.data = None\n",
        "        self.X = None\n",
        "        self.y = None\n",
        "        self.model_log_reg = LogisticRegression(random_state=42)\n",
        "        self.model_rf = RandomForestClassifier(random_state=42)\n",
        "        self.preprocessor = None\n",
        "        self.X_processed = None\n",
        "\n",
        "    def load(self):\n",
        "        \"\"\"Load the dataset.\"\"\"\n",
        "        self.data = pd.read_excel(self.data_path)\n",
        "\n",
        "        print(f\"Data Loaded with shape: {self.data.shape}\")\n",
        "\n",
        "\n",
        "    def preprocess(self):\n",
        "        \"\"\"Preprocess the data.\"\"\"\n",
        "        # Separate features and target\n",
        "        X = self.data.drop(columns=['loan_status', 'customer_id'])\n",
        "        y = self.data['loan_status']\n",
        "\n",
        "        # Extract time features from 'transaction_date' if it exists\n",
        "        if 'transaction_date' in X.columns:\n",
        "            X['transaction_year'] = pd.to_datetime(X['transaction_date']).dt.year\n",
        "            X['transaction_month'] = pd.to_datetime(X['transaction_date']).dt.month\n",
        "            X['transaction_day'] = pd.to_datetime(X['transaction_date']).dt.day\n",
        "            X = X.drop(columns=['transaction_date'])  # Drop original column\n",
        "\n",
        "        # Convert 'term' into a numerical feature by extracting the number of months\n",
        "        X['term'] = X['term'].apply(lambda x: int(x.split()[0]))  # Extract numeric term\n",
        "\n",
        "        # Handle missing values and categorical features\n",
        "        numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "        categorical_features = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "        # Remove 'term' from categorical features list as it's now numerical\n",
        "        categorical_features = [col for col in categorical_features if col != 'term']\n",
        "\n",
        "        # Numerical transformer: handle missing values and scale numerical features\n",
        "        numerical_transformer = Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='mean')),\n",
        "            ('scaler', StandardScaler())\n",
        "        ])\n",
        "\n",
        "        # Categorical transformer: handle missing values and apply One-Hot Encoding\n",
        "        categorical_transformer = Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "            ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "        ])\n",
        "\n",
        "        # Apply transformations\n",
        "        self.preprocessor = ColumnTransformer(\n",
        "            transformers=[\n",
        "                ('num', numerical_transformer, numerical_features),\n",
        "                ('cat', categorical_transformer, categorical_features)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.X_processed = self.preprocessor.fit_transform(X)\n",
        "        self.X = self.X_processed\n",
        "        self.y = y\n",
        "        print(f\"Preprocessing complete. Processed data shape: {self.X.shape}\")\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"Train both models.\"\"\"\n",
        "        # Split data into training and testing sets\n",
        "        X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size=0.3, random_state=42)\n",
        "\n",
        "        # Train Logistic Regression model\n",
        "        self.model_log_reg.fit(X_train, y_train)\n",
        "        print(\"Logistic Regression Model Trained.\")\n",
        "\n",
        "        # Train Random Forest model\n",
        "        self.model_rf.fit(X_train, y_train)\n",
        "        print(\"Random Forest Model Trained.\")\n",
        "\n",
        "        # Save models to disk\n",
        "        joblib.dump(self.model_log_reg, 'log_reg_model.pkl')\n",
        "        joblib.dump(self.model_rf, 'rf_model.pkl')\n",
        "\n",
        "    def test(self):\n",
        "        \"\"\"Test the models and generate evaluation summary.\"\"\"\n",
        "        # Split data into training and testing sets\n",
        "        X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size=0.3, random_state=42)\n",
        "\n",
        "        # Predict with Logistic Regression\n",
        "        y_pred_log_reg = self.model_log_reg.predict(X_test)\n",
        "        log_reg_accuracy = accuracy_score(y_test, y_pred_log_reg)\n",
        "        print(f\"Logistic Regression Accuracy: {log_reg_accuracy}\")\n",
        "\n",
        "        # Predict with Random Forest\n",
        "        y_pred_rf = self.model_rf.predict(X_test)\n",
        "        rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "        print(f\"Random Forest Accuracy: {rf_accuracy}\")\n",
        "\n",
        "\n",
        "    def predict(self, new_data):\n",
        "        \"\"\"Predict the loan status for new data.\"\"\"\n",
        "        # Preprocess new data\n",
        "        X_new_processed = self.preprocessor.transform(new_data)\n",
        "\n",
        "        # Predict with both models\n",
        "        pred_log_reg = self.model_log_reg.predict(X_new_processed)\n",
        "        pred_rf = self.model_rf.predict(X_new_processed)\n",
        "\n",
        "        return pred_log_reg, pred_rf\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize model\n",
        "    model = LoanStatusModel('train_data.xlsx')\n",
        "\n",
        "    # Load data\n",
        "    model.load()\n",
        "\n",
        "    # Preprocess data\n",
        "    model.preprocess()\n",
        "\n",
        "    # Train models\n",
        "    model.train()\n",
        "\n",
        "    # Test models\n",
        "    model.test()\n",
        "\n",
        "    # Load test data\n",
        "    test_data_path = \"./test_data.xlsx\"\n",
        "    test_data = pd.read_excel(test_data_path)\n",
        "\n",
        "    # Preprocess the test data to align with training data preprocessing\n",
        "    if 'transaction_date' in test_data.columns:\n",
        "        test_data['transaction_year'] = pd.to_datetime(test_data['transaction_date']).dt.year\n",
        "        test_data['transaction_month'] = pd.to_datetime(test_data['transaction_date']).dt.month\n",
        "        test_data['transaction_day'] = pd.to_datetime(test_data['transaction_date']).dt.day\n",
        "        test_data = test_data.drop(columns=['transaction_date'])  # Drop original column\n",
        "\n",
        "    # Ensure 'term' is converted to numerical\n",
        "    if 'term' in test_data.columns:\n",
        "        test_data['term'] = test_data['term'].apply(lambda x: int(x.split()[0]))\n",
        "\n",
        "    # Drop other unused columns\n",
        "    test_data = test_data.drop(columns=['customer_id'], errors='ignore')\n",
        "\n",
        "    # Preprocess the test data\n",
        "    X_test_processed = model.preprocessor.transform(test_data)\n",
        "\n",
        "    # Predict using both models\n",
        "    preds_log_reg = model.model_log_reg.predict(X_test_processed)\n",
        "    preds_rf = model.model_rf.predict(X_test_processed)\n",
        "\n",
        "    # Display predictions\n",
        "    print(f\"Predictions from Logistic Regression: {preds_log_reg}\")\n",
        "    print(f\"Predictions from Random Forest: {preds_rf}\")\n"
      ]
    }
  ]
}